dupenet MVP — Progress Overview
================================

PHASE 1: BLOB UTILITY (Layer A)
--------------------------------

## Step 1 — File Layer + Gateway + HTTP Origin

[x] Canonical serialization          deterministic CBOR, sorted keys (packages/physics)
[x] CID computation                  SHA256-based content addressing
[x] Chunker                          256KiB blocks, reassembly
[x] Merkle tree                      binary merkle, odd-leaf promotion
[x] FileManifestV1 schema            TypeBox schema (chunk_size, size, blocks[], merkle_root)
[x] AssetRootV1 schema               TypeBox schema (kind, original, variants, meta)
[x] PricingV1 schema                 min_request_sats, sats_per_gb, burst
[x] Block storage backend            filesystem: {base}/{h[0:2]}/{h[2:4]}/{hash}
[x] PUT /block/:cid                  SHA256 verified on receive, rejects mismatches
[x] GET /block/:cid                  serves bytes; L402-gated when LND configured, free in dev mode
[x] PUT /file/:root                  validates file_root = SHA256(canonical(manifest)), checks all blocks exist
[x] GET /file/:root                  returns manifest (in-memory Map)
[x] PUT /asset/:root                 validates asset_root = SHA256(canonical(AssetRoot)), checks file exists
[x] GET /asset/:root                 returns asset (in-memory Map)
[x] HEAD /asset/:root                returns size, kind, mime headers
[x] GET /pricing                     returns PricingV1
[x] GET /health                      gateway health check
[x] Physics unit tests               canonical, cid, chunker, merkle, reward, epoch-aggregation, availability, block-selection, event-signature (9 suites, vitest)
[x] Gateway integration test          PUT /block xN -> PUT /file -> PUT /asset -> GET -> reassemble -> verify (7 tests)
[ ] EXIF/metadata stripping           strip before hashing (mentioned in spec, not implemented)
[ ] Runtime schema validation         TypeBox schemas defined but Value.Check not called on ingest

## Step 2 — L402 Paid Fetch + Receipt Minting

[x] Mint service structure            POST /sign, GET /pubkey, GET /health (apps/mint)
[x] Ed25519 keypair load              loads from MINT_PRIVATE_KEY_HEX env var
[x] Receipt token format              Sign("R2" || host || epoch || block_cid || response_hash || price || payment_hash)
[x] LND service in docker compose     lnd v0.18.5-beta + bitcoind regtest, 2-node (alice+bob) in compose-founder.yml
[x] LND config fields                 LND_HOST, LND_MACAROON_PATH, LND_TLS_CERT_PATH in gateway + mint config
[x] LND client package                packages/lnd-client: LndClient interface, REST impl, MockLndClient for tests
[x] L402 challenge-response           GET /block returns 402 + invoice -> pay with preimage -> bytes + receipt_token
[x] Invoice store                     in-memory TTL map (payment_hash -> {cid, price, host, epoch, expiry})
[x] Invoice generation                gateway creates invoice via LndClient.createInvoice()
[x] Mint settlement check             mint calls LndClient.lookupInvoice(), verifies SETTLED + amount >= price
[x] Mint HTTP client                  gateway calls POST /sign on mint, receives receipt_token
[x] min_request_sats enforcement      price = min_request_sats used for all block fetches
[x] L402 integration tests            8 tests: 402 challenge, paid fetch, invalid/unknown/mismatch/single-use (mock LND)
[x] Client PoW receipt minting        minePoW(), buildChallengeRaw/ClientSigPayload/TokenPayload in physics
[x] Block selection (anti-special)    selectBlockIndex(), selectBlock(), verifyBlockSelection() in physics (SHA256 PRF)

## Step 3 — Node Kit + Host Registration

[x] compose-founder.yml               gateway, mint, coordinator, postgres, lnd, caddy (all with healthchecks)
[x] compose-nodekit.yml               gateway, node-agent, caddy
[x] Coordinator structure             Hono server with routes, event log, materialized views
[x] POST /host/register               registers host (stub stake verification)
[x] GET /directory                     returns host list from in-memory Map
[x] Node-agent poll loop                discover profitable CIDs → mirror from source → announce serve (complete)
[x] Mirror agent                       findProfitableTargets() queries GET /bounty/feed; mirrorCid() fetches + pushes
[x] Directory announcement             announceHost() signed registration; announceServe() signed HostServe
[x] Availability score tracking        computeAvailabilityScore() in physics + updateAllScores() in coordinator
[x] Status lifecycle                   PENDING->TRUSTED (score>=0.6), TRUSTED->DEGRADED (score<0.6), ->INACTIVE (score==0)
[x] Spot-check responder              GET /spot-check/:cid on gateway (verifies hash, no L402, no bytes)
[x] Spot-check runner                 spotCheckHost(), runAllChecks() in coordinator (injectable fetcher)
[x] SpotCheck Prisma model            hostPubkey, cid, epoch, passed, latencyMs, error
[x] POST /hosts/check                 triggers spot-checks for all active hosts, updates scores
[x] GET /hosts/:pubkey/checks         returns check history + availability score + recommended status
[x] Availability tests                9 physics + 12 coordinator tests (scoring, transitions, spot-check runner)
[ ] Stake locking via LND              TODO: verify stake payment
[x] CID selection agent                queries GET /bounty/feed, filters by minBounty, mirrors top profitability CIDs

## Step 4 — Receipt Verification SDK

[x] VerifyReceiptV2 function           packages/receipt-sdk, full verification logic
[x] Ed25519 verify                     Web Crypto API, zero dependencies
[x] PoW hash check                     H(challenge || nonce) < TARGET validation
[x] Client signature check             Ed25519 sig over receipt payload
[x] Zero external dependencies         only crypto.subtle
[x] Test vectors                       valid e2e receipt (construct -> verify), invalid hex/PoW/token, wrong mint key (7 tests)

## Step 5 — Pin Contracts

[x] PinContractV1 schema               TypeBox schema (physics) + Prisma model
[x] POST /pin                           creates pin, computes drain_rate, credits bounty pool, logs event
[x] GET /pin/:id                        returns status, remaining budget, active hosts, copies_met, epoch proofs
[x] POST /pin/:id/cancel               returns remaining budget minus 5% fee, status -> CANCELLED
[x] Drain rate enforcement              drainPinBudgets() deducts min(actualDrain, drainRate) per epoch
[x] Budget management                   creditBountyDirect (no protocol fee); debitPayout on cancel refund
[x] Lifecycle transitions               ACTIVE -> EXHAUSTED (when remainingBudget=0); ACTIVE -> CANCELLED (on cancel)
[x] min_copies check                    getPinStatus compares active hosts vs min_copies, returns copies_met
[x] Epoch proof bundle                  getPinStatus returns recent EpochSummaryRecords for pinned asset (last 6 epochs)
[x] Pin contract tests                  22 tests: validation, create, status, cancel, drain rate, exhaustion
[x] Pin ID deterministic                SHA256(canonical(pin content)) — duplicate detection via unique constraint

COORDINATOR — PERSISTENCE + AGGREGATION
-----------------------------------------

[x] Prisma schema                      Event, BountyPool, Host, HostServe, EpochSummaryRecord, PinContract
[x] Prisma client generated            in Dockerfile (npx prisma generate)
[x] POST /tip                          credits bounty pool (in-memory Map, stub sig verification)
[x] GET /bounty/:cid                   reads from in-memory Map
[x] Event log writer                   in-memory array (not persisted)
[x] Bounty pool view                   in-memory Map
[x] Host registry view                 in-memory Map
[x] Epoch math                         packages/physics: epoch length 4h, current epoch, epoch boundaries
[x] Reward formulas                    cidEpochCap, computeHostScore, distributeRewards (physics)
[x] EpochSummary schema                defined in physics
[x] Coordinator -> Postgres             bounty-pool, host-registry, event-log all use PrismaClient (tsc clean)
[x] Event log persistence               append-only Postgres via prisma.event.create
[x] POST /receipt/submit                validates via receipt-sdk, checks epoch range + replay, stores in Prisma
[x] Receipt validation pipeline         verifyReceiptV2 checks client_sig, PoW, receipt_token against mint pubkeys
[x] Epoch aggregation (physics)         aggregateReceipts(), isPayoutEligible() — pure receipt grouping + 5/3 threshold
[x] Epoch settlement (coordinator)      settleEpoch() — aggregate receipts, compute payouts, drain bounty, persist EpochSummary
[x] POST /epoch/settle                  validates epoch is closed, calls settleEpoch(), idempotent (no double-spend)
[x] GET /epoch/summary/:epoch           returns settlement results for a given epoch
[x] Payout execution                    distributeRewards() called by settleEpoch(), rewards split by host score
[x] Bounty drain                        cidEpochCap() limits per-epoch drain, debitPayout() debits pool
[x] Aggregator fee                      3% deducted from cap before host distribution
[x] Epoch settlement tests              8 coordinator tests (mock Prisma) + 12 physics aggregation tests
[x] Epoch boundary trigger              createEpochScheduler() auto-settles closed epochs; configurable interval + spot-checks
[x] Signature verification on events    Ed25519 verify on POST /tip and POST /host/register; rejects forged/missing sigs

DOCKER / DEPLOY
-----------------

[x] compose-founder.yml                bitcoind + lnd-alice + lnd-bob + gateway + mint + coordinator + postgres + caddy
[x] compose-nodekit.yml                gateway + node-agent + caddy (separate Caddyfile)
[x] Dockerfiles (4 apps)               multi-stage node:20-alpine builds (gateway, mint, coordinator, node-agent)
[x] Coordinator entrypoint             prisma db push --skip-generate on startup (idempotent)
[x] LND credential sharing             lnd-data volume mounted read-only to gateway + mint
[x] LND REST wiring                    gateway + mint create LndRestClient when macaroon exists (dev mode fallback)
[x] @noble/ed25519 sha512 setup        mint signer configures sha512Sync from @noble/hashes
[x] Caddyfile.founder                  gateway + coordinator routes (/spot-check, /epoch, /hosts added)
[x] Caddyfile.nodekit                  gateway-only routes
[x] scripts/gen-keys.sh                generates Ed25519 keypairs (host + 3 mints), writes .env.local
[x] scripts/fund-lnd.sh                funds alice + bob, opens 1M sat channel
[x] scripts/e2e.sh                     E2E test skeleton (needs polish for receipt/settle path)
[x] Startup config echo                all 4 apps print config on boot (port, LND mode, mint keys, genesis)
[x] GENESIS_TIMESTAMP_MS env var       coordinator + gateway; enables epoch boundary control for testing
[x] @types/node for Docker builds      physics + receipt-sdk; fixes Web Crypto type errors in Docker context
[x] Buffer.slice() fix (ed25519)       wcBuf() helper handles cbor-x Buffer views correctly

INTEGRATION / E2E
------------------

[x] Gateway round-trip test             upload multi-block file, retrieve by asset_root, verify SHA256 (7 tests)
[x] L402 flow test                      402 -> pay invoice -> receive block + receipt_token (8 tests, mock LND)
[x] Docker E2E                          FULL PASS: upload → 402 → bob pays → block + receipt_token → tip → receipt submit → epoch settle ✓
[x] Receipt round-trip test             construct valid receipt (PoW + mint sig + client sig) -> verifyReceiptV2 passes
[x] Epoch settlement test              mock Prisma: eligible/ineligible hosts, bounty drain, idempotency, score split
[x] Pin contract test                  mock Prisma: create/status/cancel, drain rate, exhaustion, validation (22 tests)
[x] Availability test                  mock Prisma + mock fetcher: spot-check, scoring, transitions (12 tests)
[x] Event signature test               real Ed25519 keypairs: signed tip/register accepted, forged/missing rejected (7 tests)
[x] Bounty feed + host/serve test     bounty feed returns profitable CIDs; signed serve announcements (6 tests)
[x] Node-agent poll cycle test        mock fetch: discover, mirror, error handling (6 tests)
[x] Epoch scheduler test             mock Prisma: tick settles, idempotent, start/stop, error handling (7 tests)

SPRINT ORDER (Phase 1 — complete)
-----------------------------------

1. Gateway integration tests            DONE (7 tests pass)
2. L402 + mint settlement               DONE (8 tests pass, mock LND; Docker E2E with real LND in sprint 6)
3. Coordinator -> Postgres              DONE (tsc clean; requires `prisma db push` + Postgres to run)
4a. Receipt submission + validation     DONE (receipt-sdk e2e test passes; coordinator handler typechecks)
4b. Epoch aggregation + payout          DONE (20 new tests: 12 physics + 8 coordinator; bounty drains correctly)
5. Pin contracts lifecycle              DONE (22 new tests; create, cancel, drain rate, exhaustion all work)
6. Docker E2E                           DONE — full pipeline: upload → L402 paid fetch → tip → receipt submit → epoch settle


================================================================================
PATH A: DEPLOY + CLI (get content flowing)
================================================================================

Goal: founder can upload seed content, share links, people can fetch via L402.
DocRef: MVP_PLAN:§Bootstrap Sequence (Week 1-2), §What Layer A Markets Need

## Sprint 7 — CLI client (apps/cli)

The minimum tool for a human to use the protocol without curl.
Wraps the HTTP API into a command-line workflow.

[x] Project scaffold                    apps/cli, TypeScript, imports @dupenet/physics, commander
[x] `dupenet upload <file>`             chunk → PUT /block × N → PUT /file → PUT /asset → print asset_root
    - chunker + manifest + asset root construction (reuse physics)
    - multi-block upload with progress indicator
    - MIME auto-detect from extension, auto kind (TEXT/IMAGE/AUDIO/VIDEO/FILE)
    - print shareable URL: https://<gateway>/asset/<root>
[x] `dupenet fetch <cid> [-o file]`     GET /asset → GET /file → stream GET /block × N → reassemble → write
    - auto-detect: raw CID (single block) vs asset_root (multi-block)
    - L402 flow: get 402 → pay invoice via LND REST → present preimage → receive bytes
    - --free flag fails instead of paying (for dev mode gateways)
    - SHA256 integrity verification on reassembly
[x] `dupenet tip <cid> <sats>`          sign tip → POST /tip → print bounty balance
    - Ed25519 sign from local keyfile (~/.dupenet/key.json)
    - print pool_credit + protocol_fee
[x] `dupenet pin create <asset_root>`   POST /pin → print pin_id, drain_rate
    - --budget, --duration, --copies flags
    - `dupenet pin status <pin_id>` → GET /pin/:id
    - `dupenet pin cancel <pin_id>` → POST /pin/:id/cancel
[x] `dupenet info <cid>`                GET /bounty/:cid + GET /asset/:root → print summary
    - bounty balance, asset metadata, gateway pricing
[x] `dupenet keygen`                    generate Ed25519 keypair → write to ~/.dupenet/key.json
    - reuse physics generateKeypair()
    - --force to overwrite existing
    - print pubkey hex
[x] `dupenet config`                    gateway URL, coordinator URL, key path, LND connection
    - ~/.dupenet/config.json
    - env var overrides (DUPENET_GATEWAY, DUPENET_COORDINATOR, DUPENET_KEY_PATH)
[x] `dupenet hosts`                     GET /directory → print host list + pricing + status
[x] LND payment integration             pay L402 invoices via LND REST (/v2/router/send)
    - connect to user's LND (REST, macaroon auth)
    - fallback: print invoice + prompt for manual wallet payment

Exit: `dupenet upload cat.jpg` → prints asset_root URL → `dupenet fetch <root> -o out.jpg` → identical file.
      `dupenet tip <root> 100` → bounty pool credited.

## Sprint 8 — Real deployment (founder stack on VPS)

The founder stack moves from Docker-on-laptop to a public server.
DocRef: MVP_PLAN:§Node Kit, §What Hosts vs What You Host, §Bootstrap Sequence, §Infrastructure Partners

[x] VPS provisioning                    FlokiNET Romania (4 CPU, 4GB RAM, 90GB NVMe, 9TB BW, DDoS prot.)
[x] Domain acquired                     ocdn.is (ISNIC Iceland — ccTLD, seizure-proof, WHOIS privacy)
[~] DNS A record                        ocdn.is → 185.165.169.8 (pending ISNIC activation)
[x] compose-production.yml              signet LND, hardened Postgres, restart policies, no regtest services
[x] Caddyfile.production                ocdn.is domain, automatic HTTPS via Caddy/Let's Encrypt
[x] scripts/deploy.sh                   one-shot server setup (Docker, git, keys, firewall)
[x] scripts/backup.sh                   Postgres dump + LND SCB, 14-day retention, cron-ready
[x] .env.example updated                production DB creds, signet macaroon paths, ocdn.is endpoint
[ ] Server access                       VPS provisioned, awaiting Proxmox lock clear (FlokiNET support)
[ ] Docker + stack deploy               deploy.sh → compose-production.yml up
[ ] LND signet wallet                   create wallet, fund via signet faucet, open channel
    - decision: signet first, flip to mainnet when confident
[ ] Mint 1 operational                  co-located on founder VPS (Romania)
[ ] Mint 2 (remote)                     separate VPS in Malaysia (Shinjiru) or Switzerland (COIN.HOST)
[ ] Mint 3 (remote)                     third jurisdiction — add before public announcement
[ ] Seed content upload                 founder uploads Tier 1 + Tier 2 content via CLI
[ ] Shareable URLs                      https://ocdn.is/asset/<root> returns content
[ ] Monitoring                          uptime check, LND balance alerts, disk usage
[ ] Backup cron                         schedule scripts/backup.sh every 6h

Exit: public URL serves real content via L402. External client can `dupenet fetch` from anywhere.

## Sprint 9 — Multi-host (prove the network)

Second host connects to the founder's coordinator and mirrors content.
DocRef: MVP_PLAN:§Node Kit (Target: Raspberry Pi), §Bounty Pool Mechanics

[ ] Second VPS (or Pi)                  deploy compose-nodekit.yml pointing at founder coordinator
[ ] Node-agent mirrors content          agent discovers bounty feed, mirrors top CIDs from founder gateway
[ ] Directory shows 2 hosts             GET /directory lists both with pricing + availability
[ ] Spot-checks pass                    coordinator verifies second host has blocks (GET /spot-check)
[ ] Failover works                      kill host 1 → client retries host 2 → content still available
[ ] CLI host selection                  `dupenet fetch` picks cheapest/fastest host from directory
[ ] Receipt flow from second host       L402 fetch from host 2 → receipt → epoch settlement includes both hosts

Exit: two independent hosts serve the same CID. Kill one, content survives. Receipts flow from both.


================================================================================
PATH A.1: DISCOVERY + SIGNALS (no VPS dependency — build while waiting)
================================================================================

Goal: content is discoverable, quotable, and actionable by humans and foreign peers.
All work is on schemas, CLI, coordinator API, and web surface — unblocked by VPS.
DocRef: MVP_PLAN:§Visibility is derived not curated, §Bootstrap Sequence, §Longevity L2/L4

Design context:
  - Every protocol action (tip, serve, receipt) is a signed event referencing a CID.
  - Events propagate via gossip (Nostr relays, peer exchange) — coordinator is one materializer, not the authority.
  - Content grouping is an event (AssetListV1), not a protocol entity — keeps Layer A dumb.
  - Reputation signals are automatic exhaust from protocol operation (receipts, spot-checks, tips), not ratings.
  - Quotes come from sampling real host thresholds, not from formulas.
  - Previews (thumbnails, excerpts) drive consumption — consumption drives receipts — receipts drive the economic loop.

## Sprint 7b — Discovery Event Schemas (packages/physics)

Event kinds for content announcement, grouping, and signal propagation.
Foundation layer — everything in discovery/metadata depends on these schemas.

[ ] ContentAnnounceV1 schema           signed event: cid, title, description, mime, size, language, tags, preview, source
    - TypeBox schema in physics (same pattern as TipV1, HostServeV1)
    - canonical serialization + event_id = SHA256(canonical(content))
    - Ed25519 signature verification
    - preview field: { type: "image/jpeg", data: "<base64>" } or { type: "text/plain", excerpt: "..." }
    - max inline preview: 16 KiB (fits in Nostr event payload)
    - optional fields: source_url (provenance), author_name, created_date (content date, not upload)
[ ] AssetListV1 schema                 signed event: title, description, items[{cid, name, mime, size}], tags, language
    - content-addressed: list_cid = SHA256(canonical(AssetListV1))
    - items reference asset_root CIDs
    - enables collection fan-out (tips distributed across constituents)
[ ] Host profitability threshold        add min_bounty_sats to PricingV1 or host registration
    - node-agent already has minBounty config — publish it in directory
    - enables client-side supply curve estimation for market quoting
[ ] Event kind constants               CONTENT_ANNOUNCE, ASSET_LIST, TIP, HOST_SERVE, RECEIPT_SUBMIT, EPOCH_SUMMARY
    - integer kind IDs (Nostr NIP-compatible range for future relay publishing)
    - version: u8 in every event (spec requirement: wire rules)
[ ] Event schema tests                 construct, sign, verify for ContentAnnounceV1 + AssetListV1

Exit: physics exports event schemas. ContentAnnounceV1 and AssetListV1 are constructable,
      signable, verifiable. Client can build an announcement, sign it, another client verifies.

## Sprint 7c — Batch Upload + Content Metadata (apps/cli)

The whistleblower flow: upload a directory of PDFs with human-readable metadata.

[ ] `dupenet upload <dir>`              batch upload: chunk + upload each file in directory
    - recursive traversal, filters by known MIME types
    - progress: file N/M, blocks K/T overall
    - skip already-uploaded blocks (409 Conflict = ok, resume on failure)
    - configurable concurrency (parallel block uploads)
[ ] Upload metadata flags               --title, --description, --tags, --language, --source
    - per-file item name derived from filename (strip extension, sanitize)
    - collection-level metadata from flags
[ ] Thumbnail generation                generate preview thumbnails client-side
    - images: resize to 200px wide JPEG (sharp or similar)
    - text/PDF: extract first 500 chars as text excerpt
    - thumbnails uploaded as blobs (own CIDs, referenced in AssetRoot.thumbs)
[ ] ContentAnnounceV1 publishing        publish per-file discovery event after upload
    - signed with uploader's key
    - inline preview (base64 thumbnail or text excerpt, ≤16 KiB)
    - POST to coordinator; event stored for discovery queries
[ ] AssetListV1 publishing              publish collection event after batch upload completes
    - groups all uploaded assets with filenames + metadata
    - signed, content-addressed (list_cid)
    - print shareable collection URL: https://<gateway>/c/<list_cid>
[ ] Collection fan-out tip              `dupenet tip <list_cid> <sats>` resolves list → tips each constituent
    - proportional by file size (larger files get proportionally more)
    - prints per-asset allocation + total pool credits

Exit: `dupenet upload ~/leak/ --title "Court Filings" --tags epstein,legal`
      → uploads 200 PDFs with thumbnails, prints collection URL.
      `dupenet tip <list_cid> 10000` → 10,000 sats distributed across 200 assets.

## Sprint 7d — Signal Aggregation + Market Quoting (apps/coordinator)

Surface reputation/resilience signals from data already in Prisma.
Enables host comparison, content resilience assessment, and market-based quoting.

[ ] GET /host/:pubkey/scorecard         automatic host reputation profile
    - uptime % (from spot-checks: rolling 30-day + lifetime)
    - median response latency (from spot-check latencyMs)
    - total receipts served (lifetime) + unique clients
    - CIDs served count + tenure (epochs since registration)
    - earned sats (sum from EpochSummaryRecords)
    - slash count (0 for honest hosts), audit challenges received + results
    - pricing + min_bounty_sats threshold
    - regions
[ ] GET /content/:cid/signals           content resilience signals
    - bounty pool balance + tip count + unique tippers
    - replica count (hosts serving) + host diversity (regions)
    - receipt velocity (fetches/epoch, recent trend)
    - unique clients (last 30 days, from receipts)
    - epoch survival (consecutive epochs with active receipts)
    - estimated sustainability (epochs remaining at current drain rate)
    - composite resilience score (0-10, formula over above inputs)
[ ] GET /author/:pubkey/profile         pseudonymous author reputation
    - content count (announcements from this pubkey)
    - total demand attracted (receipts across their content)
    - external funding (tips from other pubkeys on their content)
    - unique supporters (distinct tippers)
    - self-hosts flag (pubkey matches a registered host?)
    - first seen epoch
[ ] GET /market/quote                   market-based durability quote
    - input: cid (or list_cid), additional_sats
    - samples host directory min_bounty_sats thresholds
    - returns: current_copies, estimated_copies_after, estimated_days_sustained
    - supply curve: [{bounty_level, hosts_willing}] for display
[ ] Content metadata storage            coordinator persists discovery events
    - Prisma models: ContentAnnounce, AssetList
    - POST /content/announce — store + index ContentAnnounceV1
    - POST /content/list — store + index AssetListV1
    - GET /content/list/:list_cid — resolve collection
    - GET /content/recent — recent announcements (browsable feed, paginated)
    - GET /content/search?q=&tags= — filter by tags, title text

Exit: GET /host/<pk>/scorecard returns full automatic reputation.
      GET /content/<cid>/signals returns resilience + market quote.
      GET /content/recent returns a browsable feed of announced content.

## Sprint 7d.1 — Event Log Compaction + Snapshot Bootstrap (packages/physics + apps/coordinator)

Event stream grows without bound. At scale, new nodes can't replay from genesis.
Snapshots with inclusion proofs enable fast bootstrap; receipt rollups reduce gossip volume.
Design the format now (MVP may not exercise full anchoring), so the transition
from "trust the coordinator" to "verify against Bitcoin" is config, not architecture.
DocRef: MVP_PLAN:§Event Log Growth + Compaction, §Longevity L7

[ ] StateSnapshotV1 schema             physics: epoch, merkle roots for each state domain, event_count, prev_hash
    - bounty_pools: MerkleRoot (all cid → balance pairs)
    - host_registry: MerkleRoot (all host_pubkey → status, stake, score, pricing)
    - content_index: MerkleRoot (all cid → announce_id, list_ids)
    - host_serves: MerkleRoot (all host → cid pairs)
    - pin_contracts: MerkleRoot (all active pins)
    - snapshot_hash = SHA256(canonical(StateSnapshotV1 minus snapshot_hash))
[ ] Merkle tree library                physics: build tree from sorted key-value pairs, generate inclusion proofs, verify proofs
    - deterministic: same inputs always produce same root
    - O(log N) inclusion proof per entry
    - compatible with existing binary merkle (packages/physics/src/merkle.ts)
[ ] Snapshot generator                 coordinator: materialize current Prisma state into StateSnapshotV1
    - triggered at epoch boundaries (every SNAPSHOT_INTERVAL_EPOCHS = 100 epochs)
    - builds merkle trees from BountyPool, Host, HostServe, PinContract tables
    - stores snapshot in Postgres (or as content-addressed blob)
[ ] GET /snapshot/latest               returns most recent snapshot + epoch number
[ ] GET /snapshot/:epoch               returns snapshot at specific epoch boundary
[ ] GET /snapshot/:epoch/proof/:key    returns merkle inclusion proof for a specific entry
    - e.g. proof that CID X has bounty Y in the snapshot at epoch N
[ ] Receipt rollup in epoch settlement EpochSummary stores receipt merkle_root + counts only
    - raw individual receipts archived (queryable) but not propagated in gossip
    - reduces event stream volume at scale (receipts are highest-volume event type)
[ ] GET /bootstrap                     fast node sync: returns latest snapshot + events since snapshot
    - new node calls this instead of replaying full history
    - response: { snapshot: StateSnapshotV1, events_since: Event[], current_epoch: u32 }
[ ] Snapshot verification              verify snapshot_hash against published epoch_root
    - MVP: trust coordinator signature on snapshot (same trust model as current coordinator)
    - Future: verify against Bitcoin-anchored epoch_root (when L7 active)
    - Verification is O(1): check hash, optionally check BTC anchor
[ ] Snapshot + inclusion proof tests   physics: build snapshot, generate proof, verify proof, tamper detection
    - verify correct root from known data
    - verify inclusion proof for specific key
    - reject proof against wrong root / tampered data

Exit: coordinator generates snapshots every 100 epochs. GET /bootstrap returns snapshot + recent events.
      New node materializes state from snapshot (seconds, not hours). Inclusion proof verifies
      "CID X has bounty Y" against snapshot merkle root in O(log N).

## Sprint 7e — Web Content Surface

The page that makes content visible and actionable. The recipient of a shared link
sees content, resilience signals, and a Fortify button. This IS the product.

[ ] Scaffold web app                   apps/web (or extend gateway), Next.js or static + API calls
    - minimal: server-renders from coordinator + gateway APIs
    - no auth required for viewing (read-only by default)
[ ] Content landing page: /v/<cid>     single asset view
    - header: title, description (from ContentAnnounceV1), kind, mime, size
    - preview: thumbnail image or text excerpt (from event or free-served thumb blob)
    - instrument cluster: bounty balance, replica count, epoch survival, demand trend
    - host list: who serves this, availability %, pricing
    - Fortify button: amount presets (100 / 1,000 / 10,000 sats) + custom
[ ] Collection page: /c/<list_cid>     grouped content view
    - collection title, description, total size, document count
    - item list: name, mime, size, individual bounty, mini-preview
    - aggregate resilience: total bounty, weakest-link replicas, overall sustainability
    - Fortify button: fan-out tip across all assets
    - expandable per-asset detail (individual signals, fetch link)
[ ] Market quote display               "Add X sats → est. Y copies for Z days"
    - calls GET /market/quote, displays supply curve visually
    - preset amounts show estimated impact before payment
    - updates after successful payment
[ ] Lightning payment (browser)        Fortify button payment flow
    - WebLN detection (Alby etc.): auto-pay on click
    - Fallback: display Lightning invoice as QR code + copy-paste
    - on settlement: POST /tip (or fan-out for collections), refresh signals
[ ] Free preview serving               gateway serves thumbnails without L402
    - thumb CIDs (from AssetRoot.thumbs) bypass L402 gate
    - or: any GET /block/:cid where block_size ≤ 16 KiB served free
    - enables preview rendering on landing page before any payment
[ ] Host scorecard page: /h/<pubkey>   host reputation view
    - renders GET /host/:pubkey/scorecard as readable profile
    - uptime chart (recent epochs), latency, capacity, pricing
    - link from content page host list

Exit: share https://ocdn.is/c/<list_cid> → recipient sees collection with titles, previews,
      resilience scores, and Fortify button. One click + Lightning payment to fund replication.


================================================================================
PATH B: S3 ADAPTER (platform adoption)
================================================================================

Goal: existing apps switch to dupenet storage with a config change.
DocRef: MVP_PLAN:§S3-Compatible Adapter (Layer A — Migration Unlock)

## Sprint 10 — S3-compatible adapter (apps/s3-adapter)

Thin shim that speaks S3 protocol and translates to the blob layer.
Single-tenant: runs alongside the consuming app, talks to one gateway.

[ ] Project scaffold                    apps/s3-adapter, TypeScript + Fastify (or http)
[ ] Auth layer                          S3 access key → protocol pubkey mapping (thin translation)
    - single-user mode for MVP (one access key)
    - SigV4 signature verification (just enough to satisfy AWS SDKs)
[ ] PUT object → chunk + upload         receive S3 PutObject → chunk file → PUT /block × N → PUT /file → PUT /asset
    - compute asset_root, return as ETag
    - handle multipart uploads (S3 multipart → map to block uploads)
    - chunking reuses @dupenet/physics
[ ] GET object → resolve + stream       S3 GetObject → GET /asset → GET /file → stream GET /block × N
    - reassemble blocks into response stream
    - Range header support (partial reads)
    - Content-Type from AssetRoot mime
[ ] HEAD object                         S3 HeadObject → HEAD /asset → return size, content-type, ETag
[ ] DELETE object                       return 204 (no-op; content-addressed = no true delete)
[ ] LIST objects                        return list of known asset_roots (local cache)
    - or: return empty (many apps don't need LIST)
[ ] Bucket abstraction                  all objects in one "bucket" (single gateway = single bucket)
[ ] Integration test                    `aws s3 cp` in, `aws s3 cp` out, `aws s3 ls` → identical bytes
[ ] Docker image                        add to compose-founder.yml as optional service

Exit: `aws s3 cp file.tar s3://dupenet/file.tar` succeeds.
      `aws s3 cp s3://dupenet/file.tar -` returns identical bytes.
      No code changes in the consuming app.

## Sprint 11 — SDK + documentation

Make Layer A consumable by external developers.
DocRef: MVP_PLAN:§Receipt Verification SDK, §Adoption Path

[ ] receipt-sdk published               npm publish @dupenet/receipt-sdk (zero deps, works everywhere)
[ ] physics published                   npm publish @dupenet/physics (or subset: canonical, cid, chunker)
[ ] HTTP API reference                  OpenAPI/Swagger spec for gateway + coordinator endpoints
    - generated from route definitions or hand-written
    - hosted at docs.dupenet.dev
[ ] Integration guide                   "Store files on dupenet in 5 minutes"
    - code samples: upload, fetch, tip, pin
    - S3 adapter setup guide
[ ] Receipt verification guide          "Verify paid consumption in your app"
    - import receipt-sdk → verify receipts → rank content / gate access
    - cross-platform use cases (Nostr, forums, media apps)
[ ] Pin contract guide                  "Pay for durability"
    - create pin, monitor copies, cancel/refund flow

Exit: a developer who has never seen the codebase can integrate in <1 hour.


================================================================================
REMAINING POLISH (non-blocking, do when convenient)
================================================================================

[ ] EXIF/metadata stripping             strip before hashing (mentioned in spec, not implemented)
[ ] Runtime schema validation           TypeBox schemas defined but Value.Check not called on ingest
[ ] Stake locking via LND               verify stake payment on host registration (currently stubbed)
[ ] Deterministic Docker builds         Nix flake or pinned multi-stage (DocRef: MVP_PLAN:§Longevity L6)
[ ] Epoch root anchoring                Bitcoin tx per epoch: SHA256(epoch_summary_root || snapshot_hash) (DocRef: MVP_PLAN:§Longevity L7)
    - makes state snapshots trustlessly verifiable (no need to trust coordinator)
    - depends on Sprint 7d.1 (snapshot format must exist first)
    - Taproot tweak or OP_RETURN, ~$0.50/day at 1 tx/day covering 6 epochs


LEGEND: [x] done  [~] partial/stub  [ ] not started
